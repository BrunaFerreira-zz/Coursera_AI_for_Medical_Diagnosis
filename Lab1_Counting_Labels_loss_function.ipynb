{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab1_Counting_Labels_loss_function.ipynb",
      "provenance": [],
      "mount_file_id": "1a7llLYhNgSeDjeXREDRVYfW_Qrf3HzYt",
      "authorship_tag": "ABX9TyNL1t4rDtkzJYNfVtY7k3jE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunaFerreira/Coursera_AI_for_Medical_Diagnosis/blob/master/Lab1_Counting_Labels_loss_function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEpHHVo9LPXy"
      },
      "source": [
        "# Contando rótulos (labels) e definindo função de custo (loss function)\r\n",
        "* AI for Medicine Course 1 Week 1 lecture exercises\r\n",
        "* AI4M_C1_W1_lecture_ex_02\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSEbFDc52uQp"
      },
      "source": [
        "# Import pacotes necessários\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4FZRNm-h2gM"
      },
      "source": [
        "# Le arquivo .csv lendo dados de treinamento\r\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/0_Cursos/1. Coursera/AI Medicine /Code/data/train-small.csv\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "979hdHdY2zOv"
      },
      "source": [
        "## Contando Rótulos (Labels)\n",
        "Uma maneira de evitar que desbalanceamento das classes afete a função de perda é ponderar as perdas de forma diferente. Para escolher os pesos, primeiro você precisa calcular as frequências das classes.\n",
        "\n",
        "* Contagem de cada rótulo (label);"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG1ZpSXNhnoK"
      },
      "source": [
        "# Contando o número de instancias para cada classe\r\n",
        "class_counts = train_df.sum().drop(['Image','PatientId'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsJb0lKVhhT9"
      },
      "source": [
        "* Frequência em cada classe:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bq6Q6PvjWEQ",
        "outputId": "3b7bd55d-5062-4234-b029-fbcb76525557"
      },
      "source": [
        "for column in class_counts.keys():\r\n",
        "    print(f\"A classe {column} contém {train_df[column].sum()} amostras\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A classe Atelectasis contém 106 amostras\n",
            "A classe Cardiomegaly contém 20 amostras\n",
            "A classe Consolidation contém 33 amostras\n",
            "A classe Edema contém 16 amostras\n",
            "A classe Effusion contém 128 amostras\n",
            "A classe Emphysema contém 13 amostras\n",
            "A classe Fibrosis contém 14 amostras\n",
            "A classe Hernia contém 2 amostras\n",
            "A classe Infiltration contém 175 amostras\n",
            "A classe Mass contém 45 amostras\n",
            "A classe Nodule contém 54 amostras\n",
            "A classe Pleural_Thickening contém 21 amostras\n",
            "A classe Pneumonia contém 10 amostras\n",
            "A classe Pneumothorax contém 38 amostras\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "VaNJcNvio0HD",
        "outputId": "ceacdf1b-c0d4-48e5-c4b7-792bcca6c369"
      },
      "source": [
        "# Grafico das distribuições\r\n",
        "sns.barplot(class_counts.values, class_counts.index, color = 'b')\r\n",
        "plt.title('Distribuição de Classes para dados de treino', fontsize=15)\r\n",
        "plt.xlabel('Número de Pacientes', fontsize=15)\r\n",
        "plt.ylabel('Doenças', fontsize=15)\r\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ygPrgISsdzf"
      },
      "source": [
        "# Função de perda ponderada - Weighted Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWsduX66ssNB"
      },
      "source": [
        "Primeiro definirá um conjunto hipotético de rótulos verdadeiros e, um conjunto de previsões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCXeuwri3CMq",
        "outputId": "b2664ebe-1544-469a-9562-d85abd25dc33"
      },
      "source": [
        "# Matriz com 4 valores de rótulo binários, 3 positivos e 1 negativo\n",
        "y_true = np.array(\n",
        "        [[1],\n",
        "         [1],\n",
        "         [1],\n",
        "         [0]])\n",
        "print(f\"y_true: \\n{y_true}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_true: \n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " [0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdODbhjptQ21"
      },
      "source": [
        "### Dois modelos\r\n",
        "- O Modelo 1 sempre produz um 0,9 para qualquer exemplo fornecido.\r\n",
        "- O Modelo 2 sempre produz um 0,1 para qualquer exemplo que for fornecido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q23DRGBhbY8s"
      },
      "source": [
        "O arquivo contém:\r\n",
        "* os nomes das radiografias de tórax (coluna \"Image\"\r\n",
        "* colunas preenchidas com uns e zeros, que  identificam quais diagnósticos foram dados com base em cada radiografia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpK1kGC4taKn",
        "outputId": "7fbdb9ab-f9c7-4277-e721-fa7ef6d34b2d"
      },
      "source": [
        "# Faça previsões de modelo que são sempre 0,9 para todos os exemplos\r\n",
        "y_pred_1 = 0.9 * np.ones(y_true.shape)\r\n",
        "print(f\"y_pred_1: \\n{y_pred_1}\")\r\n",
        "print()\r\n",
        "y_pred_2 = 0.1 * np.ones(y_true.shape)\r\n",
        "print(f\"y_pred_2: \\n{y_pred_2}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_pred_1: \n",
            "[[0.9]\n",
            " [0.9]\n",
            " [0.9]\n",
            " [0.9]]\n",
            "\n",
            "y_pred_2: \n",
            "[[0.1]\n",
            " [0.1]\n",
            " [0.1]\n",
            " [0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhoGz2rhwLNe"
      },
      "source": [
        "### Problemas com a função de perda regular\r\n",
        "O objetivo do aprendizado aqui é perceber que, com uma função de perda regular (não uma perda ponderada), o modelo que sempre produz 0,9 tem uma perda menor (desempenho melhor) do que o modelo 2.\r\n",
        "\r\n",
        "Isso ocorre porque:\r\n",
        "-  há desbalanceamento de classes, em que 3 dos 4 rótulos são 1.\r\n",
        "- Se os dados estivessem perfeitamente balanceados (dois rótulos eram 1 e dois rótulos eram 0), o modelo 1 e o modelo 2 teriam a mesma perda. Cada um obteria dois exemplos corretos e dois exemplos incorretos.\r\n",
        "- Função de perda regular implica que o modelo 1 é melhor do que o modelo 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OzX9BRowt0P"
      },
      "source": [
        "### Observe as deficiências de uma perda não ponderada regular\r\n",
        "\r\n",
        "Lembrando que o modelo 1 sempre prevê 0,9 e o modelo 2 sempre prevê 0,1, veja a função de perda regular (não ponderada) para cada modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMXzAK6-w60G",
        "outputId": "9edb4cc5-bd0e-4e74-ea40-d3c84e5997ea"
      },
      "source": [
        "loss_reg_1 = -1 * np.sum(y_true * np.log(y_pred_1)) + \\\r\n",
        "                -1 * np.sum((1 - y_true) * np.log(1 - y_pred_1))\r\n",
        "print(f\"loss_reg_1: {loss_reg_1:.4f}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_reg_1: 2.6187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43L2hRNkw_17",
        "outputId": "f5e542b7-b248-41f4-e29b-82e42a3149bf"
      },
      "source": [
        "loss_reg_2 = -1 * np.sum(y_true * np.log(y_pred_2)) + \\\r\n",
        "                -1 * np.sum((1 - y_true) * np.log(1 - y_pred_2))\r\n",
        "print(f\"loss_reg_2: {loss_reg_2:.4f}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_reg_2: 7.0131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ec2Vp7kxCmz",
        "outputId": "d4a81f40-fb40-4355-8f4e-95a0395cdcb6"
      },
      "source": [
        "print(f\"Quando o modelo 1 sempre prevê 0.9, a perda regular é {loss_reg_1:.4f}\")\r\n",
        "print(f\"Quando o modelo 2 sempre prevê 0.1, a perda regular é {loss_reg_2:.4f}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Quando o modelo 1 sempre prevê 0.9, a perda regular é 2.6187\n",
            "Quando o modelo 2 sempre prevê 0.1, a perda regular é 7.0131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B36veF2pxZ_g"
      },
      "source": [
        "A função de perda dá uma perda maior quando as previsões são sempre 0.1, porque os dados são desbalanceados:\r\n",
        "- três rótulos de `1`\r\n",
        "- um rótulo de` 0`.\r\n",
        "\r\n",
        "Dado um desbalanceamento de classe com rótulos mais positivos, a função de perda regular implica que o modelo com a previsão mais alta de 0,9 tem um desempenho melhor do que o modelo com a previsão mais baixa de 0,1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WrU3otk17ga"
      },
      "source": [
        "### Como uma perda ponderada trata os dois modelos da mesma maneira\r\n",
        "Com uma função de perda ponderada,será obtida a mesma perda ponderada quando as previsões forem todas 0,9 ou quando forem todas 0,1.\r\n",
        "- Uma previsão de 0,9 está a 0,1 de distância do rótulo positivo de 1.\r\n",
        "- Uma previsão de 0,1 está a 0,1 de distância do rótulo negativo de 0\r\n",
        "- Portanto, os modelos 1 e 2 são \"simétricos\" ao longo do ponto médio de 0,5, em uma reta numérica entre 0 e 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTHLlh_S17ob"
      },
      "source": [
        "### Equação de perda ponderada\r\n",
        "Calcule a perda para o zero-ésimo rótulo (coluna no índice 0).\r\n",
        "\r\n",
        "- A perda é composta por dois termos:\r\n",
        "\r\n",
        "    - $loss_{pos}$: perda em que o rótulo real é positivo (os exemplos positivos).\r\n",
        "    - $loss_{neg}$: perda em que o rótulo real é negativo (os exemplos negativos).\r\n",
        "\r\n",
        "$$ loss^{(i)} = loss_{pos}^{(i)} + los_{neg}^{(i)} $$\r\n",
        "\r\n",
        "$$loss_{pos}^{(i)} = -1 \\times weight_{pos}^{(i)} \\times y^{(i)} \\times log(\\hat{y}^{(i)})$$\r\n",
        "\r\n",
        "$$loss_{neg}^{(i)} = -1 \\times weight_{neg}^{(i)} \\times (1- y^{(i)}) \\times log(1 - \\hat{y}^{(i)})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AA9nBLx17v1"
      },
      "source": [
        "- Para obter o peso positivo, conte quantos rótulos NEGATIVOS estão presentes, dividido pelo número total de exemplos.\r\n",
        "\r\n",
        "Nesse caso, há um rótulo negativo e quatro exemplos no total.\r\n",
        "\r\n",
        "Da mesma forma, o peso negativo é a fração de rótulos positivos.\r\n",
        "\r\n",
        "Execute a próxima célula para definir os pesos positivos e negativos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JijhUEtn4OMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b3f44ad-50f0-4a2b-88f3-4aeeb43177dd"
      },
      "source": [
        "# calculate the positive weight as the fraction of negative labels\r\n",
        "w_p = 1/4\r\n",
        "\r\n",
        "# calculate the negative weight as the fraction of positive labels\r\n",
        "w_n = 3/4\r\n",
        "\r\n",
        "print(f\"positive weight w_p: {w_p}\")\r\n",
        "print(f\"negative weight w_n {w_n}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive weight w_p: 0.25\n",
            "negative weight w_n 0.75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKwltXcX4Th2"
      },
      "source": [
        "### Perda ponderada do modelo 1\r\n",
        "Execute as próximas duas células para calcular os dois termos de perda separadamente.\r\n",
        "\r\n",
        "Aqui, `loss_1_pos` e` loss_1_neg` são calculados usando as previsões `y_pred_1`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SD9hqEW74Umf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38f62ca1-f221-4b4a-9540-b3bd78f819f7"
      },
      "source": [
        "# Calculate and print out the first term in the loss function, which we are calling 'loss_pos'\r\n",
        "loss_1_pos = -1 * np.sum(w_p * y_true * np.log(y_pred_1 ))\r\n",
        "print(f\"loss_1_pos: {loss_1_pos:.4f}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_1_pos: 0.0790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8rARCtY4U29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3e5fa9a-8a2e-4c37-c647-8149f4692355"
      },
      "source": [
        "# Calculate and print out the second term in the loss function, which we're calling 'loss_neg'\r\n",
        "loss_1_neg = -1 * np.sum(w_n * (1 - y_true) * np.log(1 - y_pred_1 ))\r\n",
        "print(f\"loss_1_neg: {loss_1_neg:.4f}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_1_neg: 1.7269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks2FI5hP4ZWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83b008e-1b8d-497d-e08c-a7b1b890acf6"
      },
      "source": [
        "# Sum positive and negative losses to calculate total loss\r\n",
        "loss_1 = loss_1_pos + loss_1_neg\r\n",
        "print(f\"loss_1: {loss_1:.4f}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_1: 1.8060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKrHfxtc4ePv"
      },
      "source": [
        "### Perda ponderada do modelo 2\r\n",
        "\r\n",
        "Agora faça os mesmos cálculos para quando as previsões forem de `y_pred_2 '. Calcule os dois termos da função de perda ponderada e some-os."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOevCWfU4fUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecde08b9-7905-47d6-86a9-31721cb49b0a"
      },
      "source": [
        "# Calculate and print out the first term in the loss function, which we are calling 'loss_pos'\r\n",
        "loss_2_pos = -1 * np.sum(w_p * y_true * np.log(y_pred_2))\r\n",
        "print(f\"loss_2_pos: {loss_2_pos:.4f}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_2_pos: 1.7269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAkme_CI4fk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93d23c65-429e-4cd1-e575-b5e3e022750e"
      },
      "source": [
        "# Calculate and print out the second term in the loss function, which we're calling 'loss_neg'\r\n",
        "loss_2_neg = -1 * np.sum(w_n * (1 - y_true) * np.log(1 - y_pred_2))\r\n",
        "print(f\"loss_2_neg: {loss_2_neg:.4f}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_2_neg: 0.0790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtiZFnsH4jjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9792dff5-bfea-4739-8c33-6f178c88db84"
      },
      "source": [
        "# Sum positive and negative losses to calculate total loss when the prediction is y_pred_2\r\n",
        "loss_2 = loss_2_pos + loss_2_neg\r\n",
        "print(f\"loss_2: {loss_2:.4f}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_2: 1.8060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS1hFBTq50LE"
      },
      "source": [
        "### Compare a perda ponderada do modelo 1 e do modelo 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whRqPncK4jq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "766440d3-9b1d-4506-bbfd-b74c5b1cda04"
      },
      "source": [
        "print(f\"When the model always predicts 0.9, the total loss is {loss_1:.4f}\")\r\n",
        "print(f\"When the model always predicts 0.1, the total loss is {loss_2:.4f}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When the model always predicts 0.9, the total loss is 1.8060\n",
            "When the model always predicts 0.1, the total loss is 1.8060\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8puboMB58ZW"
      },
      "source": [
        "### O que você percebe?\r\n",
        "Como você usou uma perda ponderada, a perda calculada é a mesma, quer o modelo sempre preveja 0,9 ou sempre preveja 0,1.\r\n",
        "\r\n",
        "Você também deve ter notado que, ao calcular cada termo da perda ponderada separadamente, há um pouco de simetria ao comparar os dois conjuntos de previsões."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EWUI8454jy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad517ea5-6dbe-4f13-c425-ef3bd5d2685f"
      },
      "source": [
        "print(f\"loss_1_pos: {loss_1_pos:.4f} \\t loss_1_neg: {loss_1_neg:.4f}\")\r\n",
        "print()\r\n",
        "print(f\"loss_2_pos: {loss_2_pos:.4f} \\t loss_2_neg: {loss_2_neg:.4f}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_1_pos: 0.0790 \t loss_1_neg: 1.7269\n",
            "\n",
            "loss_2_pos: 1.7269 \t loss_2_neg: 0.0790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWU4cOmE6FH1"
      },
      "source": [
        "Mesmo que haja um desequilíbrio de classe, onde há 3 rótulos positivos, mas apenas um rótulo negativo, a perda ponderada é responsável por isso dando mais peso ao rótulo negativo do que ao positivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fH0f1Yj6KcP"
      },
      "source": [
        "### Perda ponderada para mais de uma classe\r\n",
        "\r\n",
        "Na tarefa desta semana, você calculará a perda ponderada de várias classes (quando houver mais de uma classe de doença que seu modelo está aprendendo a prever). Aqui, você pode praticar o trabalho com matrizes numpy 2D, o que o ajudará a implementar a perda ponderada de várias classes na tarefa avaliada.\r\n",
        "\r\n",
        "Você trabalhará com um conjunto de dados que possui duas classes de doenças (duas colunas)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eT_2u1X26FyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0850329d-1476-46f1-976a-7616d7b35d88"
      },
      "source": [
        "# View the labels (true values) that you will practice with\r\n",
        "y_true = np.array(\r\n",
        "        [[1,0],\r\n",
        "         [1,0],\r\n",
        "         [1,0],\r\n",
        "         [1,0],\r\n",
        "         [0,1]\r\n",
        "        ])\r\n",
        "y_true"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       [0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZK6ugPK6SMA"
      },
      "source": [
        "### Escolhendo eixo = 0 ou eixo = 1\r\n",
        "Você usará `numpy.sum` para contar o número de vezes que a coluna` 0` tem o valor 0.\r\n",
        "Primeiro, observe a diferença quando você define ` axis` = 0 versus ` axis` = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEwr4eJZ6TCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409bae36-567c-4b6d-d168-46d3f53cbe1c"
      },
      "source": [
        "# See what happens when you set axis=0\r\n",
        "print(f\"using axis = 0 {np.sum(y_true,axis=0)}\")\r\n",
        "\r\n",
        "# Compare this to what happens when you set axis=1\r\n",
        "print(f\"using axis = 1 {np.sum(y_true,axis=1)}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using axis = 0 [4 1]\n",
            "using axis = 1 [1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIpXuVCR6ZUp"
      },
      "source": [
        "Observe que se você escolher ` axis = 0`, a soma é obtida para cada uma das duas colunas. Isso é o que você deseja fazer neste caso. Se você definir `axis = 1`, a soma é obtida para cada linha."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYv5Ollz6gQT"
      },
      "source": [
        "### Calcule os pesos\r\n",
        "Anteriormente, você inspecionava visualmente os dados para calcular a fração de rótulos negativos e positivos. Aqui, você pode fazer isso programaticamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGNFdhNv6g6w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6c40d6-f4c8-4425-ccd4-de64aa2f44b1"
      },
      "source": [
        "# set the positive weights as the fraction of negative labels (0) for each class (each column)\r\n",
        "w_p = np.sum(y_true == 0,axis=0) / y_true.shape[0]\r\n",
        "w_p"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2, 0.8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHqIzVZd6hB3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c21c979-8f90-453e-bbac-667fe284e0da"
      },
      "source": [
        "# set the negative weights as the fraction of positive labels (1) for each class\r\n",
        "w_n = np.sum(y_true == 1, axis=0) / y_true.shape[0]\r\n",
        "w_n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8, 0.2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2Ytgv2i6pws"
      },
      "source": [
        "Na tarefa, você treinará um modelo para tentar fazer previsões úteis. Para tornar este exemplo mais fácil de seguir, você fingirá que seu modelo sempre prevê o mesmo valor para todos os exemplos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxVo7kEN6hIq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4a747e-33de-4a87-94c3-e835614e26be"
      },
      "source": [
        "# Set model predictions where all predictions are the same\r\n",
        "y_pred = np.ones(y_true.shape)\r\n",
        "y_pred[:,0] = 0.3 * y_pred[:,0]\r\n",
        "y_pred[:,1] = 0.7 * y_pred[:,1]\r\n",
        "y_pred"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3, 0.7],\n",
              "       [0.3, 0.7],\n",
              "       [0.3, 0.7],\n",
              "       [0.3, 0.7],\n",
              "       [0.3, 0.7]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYgrj-Ds7BFx"
      },
      "source": [
        "omo antes, calcule os dois termos que constituem a função de perda. Observe que você está trabalhando com mais de uma classe (representada por colunas). Nesse caso, existem duas classes.\r\n",
        "\r\n",
        "Comece calculando a perda para a classe `0`.\r\n",
        "\r\n",
        "\r\n",
        "$$ loss^{(i)} = loss_{pos}^{(i)} + los_{neg}^{(i)} $$\r\n",
        "\r\n",
        "$$loss_{pos}^{(i)} = -1 \\times weight_{pos}^{(i)} \\times y^{(i)} \\times log(\\hat{y}^{(i)})$$\r\n",
        "\r\n",
        "$$loss_{neg}^{(i)} = -1 \\times weight_{neg}^{(i)} \\times (1- y^{(i)}) \\times log(1 - \\hat{y}^{(i)})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so9bsCvL7KvR"
      },
      "source": [
        "Visualize a coluna zero para os pesos, valores verdadeiros e previsões que você usará para calcular a perda das previsões positivas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fNSnc_k6hNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b65ccc9-44ad-4ff2-bdee-d64b7e86a2fe"
      },
      "source": [
        "# Print and view column zero of the weight\r\n",
        "print(f\"w_p[0]: {w_p[0]}\")\r\n",
        "print(f\"y_true[:,0]: {y_true[:,0]}\")\r\n",
        "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w_p[0]: 0.2\n",
            "y_true[:,0]: [1 1 1 1 0]\n",
            "y_pred[:,0]: [0.3 0.3 0.3 0.3 0.3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye7BpZg46hZG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc34ce4-fb65-469e-d750-1da294ed1e19"
      },
      "source": [
        "# calculate the loss from the positive predictions, for class 0\r\n",
        "loss_0_pos = -1 * np.sum(w_p[0] * \r\n",
        "                y_true[:, 0] * \r\n",
        "                np.log(y_pred[:, 0])\r\n",
        "              )\r\n",
        "print(f\"loss_0_pos: {loss_0_pos:.4f}\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_0_pos: 0.9632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMpTaYeB7UOm"
      },
      "source": [
        "Visualize a coluna zero para os pesos, valores verdadeiros e previsões que você usará para calcular a perda das previsões negativas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6ug05iO6aBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8541cd98-55fa-4fae-f4bd-48460974e22c"
      },
      "source": [
        "# Print and view column zero of the weight\r\n",
        "print(f\"w_n[0]: {w_n[0]}\")\r\n",
        "print(f\"y_true[:,0]: {y_true[:,0]}\")\r\n",
        "print(f\"y_pred[:,0]: {y_pred[:,0]}\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w_n[0]: 0.8\n",
            "y_true[:,0]: [1 1 1 1 0]\n",
            "y_pred[:,0]: [0.3 0.3 0.3 0.3 0.3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIQuEj_97YFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beaeffb1-d6ca-46f3-93b4-4620ea41e1e9"
      },
      "source": [
        "# Calculate the loss from the negative predictions, for class 0\r\n",
        "loss_0_neg = -1 * np.sum( \r\n",
        "                w_n[0] * \r\n",
        "                (1 - y_true[:, 0]) * \r\n",
        "                np.log(1 - y_pred[:, 0])\r\n",
        "              )\r\n",
        "print(f\"loss_0_neg: {loss_0_neg:.4f}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_0_neg: 0.2853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1WrUv9m7YUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b08a3dd0-6707-463e-e40d-0f185f11d26d"
      },
      "source": [
        "# add the two loss terms to get the total loss for class 0\r\n",
        "loss_0 = loss_0_neg + loss_0_pos\r\n",
        "print(f\"loss_0: {loss_0:.4f}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_0: 1.2485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON66nGLN7gQh"
      },
      "source": [
        "Agora você está familiarizado com o corte de matriz que você usaria quando houver várias classes de doenças armazenadas em uma matriz bidimensional.\r\n",
        "\r\n",
        "#### Agora é sua vez!\r\n",
        "* Você pode calcular a perda para a classe (coluna) `1`?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbgCcdl7YiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8932cdc4-add8-4eac-a464-973b91e5df1f"
      },
      "source": [
        "# calculate the loss from the positive predictions, for class 1\r\n",
        "loss_1_pos = -1 * np.sum(w_p[1] * \r\n",
        "                y_true[:, 1] * \r\n",
        "                np.log(y_pred[:, 1])\r\n",
        "              )\r\n",
        "print(f\"loss_1_pos: {loss_1_pos:.4f}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_1_pos: 0.2853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF-THR-D7kPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a288e606-dbde-466a-dafd-93b9530a6746"
      },
      "source": [
        "# Calculate the loss from the negative predictions, for class 1\r\n",
        "loss_1_neg = -1 * np.sum( \r\n",
        "                w_n[1] * \r\n",
        "                (1 - y_true[:, 1]) * \r\n",
        "                np.log(1 - y_pred[:, 1])\r\n",
        "              )\r\n",
        "print(f\"loss_1_neg: {loss_1_neg:.4f}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss_1_neg: 0.9632\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQZGKKsO7kb4"
      },
      "source": [
        "# add the two loss terms to get the total loss for class 0\r\n",
        "loss_1 = loss_1_pos+loss_1_neg"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k7h5M5jUfTF",
        "outputId": "ec6d69ee-9119-4c36-9aef-450d4fa9b25c"
      },
      "source": [
        "loss_1"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2485181986117349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fej0UUWr7uYM"
      },
      "source": [
        "### Observação\r\n",
        "Os dados para as duas classes (duas colunas) assim como as previsões foram escolhidos de forma que você acabe obtendo a mesma perda ponderada para as duas categorias.\r\n",
        "  - Em geral, você espera calcular diferentes valores de perda ponderada para cada categoria de doença, pois as previsões e dados do modelo variam de uma categoria para outra."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MU5_C7XD70cd"
      },
      "source": [
        "Se desejar ajuda, clique na célula verde \"Solução\" abaixo para revelar a solução."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVVp5JZ74om"
      },
      "source": [
        "<details>    \r\n",
        "<summary>\r\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Solution</b></font>\r\n",
        "</summary>\r\n",
        "<p>\r\n",
        "<code>\r\n",
        "-- # calculate the loss from the positive predictions, for class 1\r\n",
        "loss_1_pos = -1 * np.sum(w_p[1] * \r\n",
        "                y_true[:, 1] * \r\n",
        "                np.log(y_pred[:, 1])\r\n",
        "              )\r\n",
        "print(f\"loss_1_pos: {loss_1_pos:.4f}\")\r\n",
        "    \r\n",
        "-- # Calculate the loss from the negative predictions, for class 1\r\n",
        "loss_1_neg = -1 * np.sum( \r\n",
        "                w_n[1] * \r\n",
        "                (1 - y_true[:, 1]) * \r\n",
        "                np.log(1 - y_pred[:, 1])\r\n",
        "              )\r\n",
        "print(f\"loss_1_neg: {loss_1_neg:.4f}\")\r\n",
        "\r\n",
        "-- # add the two loss terms to get the total loss for class 1\r\n",
        "loss_1 = loss_1_neg + loss_1_pos\r\n",
        "print(f\"loss_1: {loss_1:.4f}\")\r\n",
        "    </code>\r\n",
        "</p>\r\n"
      ]
    }
  ]
}